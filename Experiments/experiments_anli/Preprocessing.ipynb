{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Following is needed for connecting to google drive and setting up fairseq to for tokenization and binarization."],"metadata":{"id":"3JbS_JlX49gU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzNowqr6D-sn","executionInfo":{"status":"ok","timestamp":1686911179448,"user_tz":-120,"elapsed":15606,"user":{"displayName":"Louise Leibbrandt","userId":"08849155044420854120"}},"outputId":"51f302d0-a765-4c59-8a45-9865ab386a7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["! pip install tensorboardX\n","! pip install tensorrt"],"metadata":{"id":"pGiLyjgVECxr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install cython -U\n","!git clone https://github.com/pytorch/fairseq.git\n","%cd fairseq\n","!pip install --quiet --editable .\n","!pip install --quiet sentencepiece"],"metadata":{"id":"PPw9xAqwEFns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! mkdir -p gpt2_bpe\n","! wget -O gpt2_bpe/encoder.json https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n","! wget -O gpt2_bpe/vocab.bpe https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n","! wget -O gpt2_bpe/dict.txt https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt"],"metadata":{"id":"YWTFW0EiEF4L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Truncation\n","\n","**Run only once!!!** (r2 added for failsafe)"],"metadata":{"id":"eXQqjso75voU"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","f1 = open('/content/drive/MyDrive/NLP/anli/R1/orig/train.raw.input0', 'r')\n","f2 = open('/content/drive/MyDrive/NLP/anli/R1/orig/train.raw.input1', 'r')\n","f3 = open('/content/drive/MyDrive/NLP/anli/R1/orig/train.raw.label', 'r')\n","\n","o1 = open('/content/drive/MyDrive/NLP/anli/R1/orig/trainr2.raw.input0', 'w')\n","o2 = open('/content/drive/MyDrive/NLP/anli/R1/orig/trainr2.raw.input1', 'w')\n","o3 = open('/content/drive/MyDrive/NLP/anli/R1/orig/trainr2.raw.label', 'w')\n","\n","\n","lines1 = f1.read().splitlines()\n","lines2 = f2.read().splitlines()\n","lines3 = f3.read().splitlines()\n","\n","arr = random.sample(range(1, len(lines1)), 10000)\n","\n","for i in arr:\n","    o1.write(lines1[i].rstrip()+\"\\n\")\n","    o2.write(lines2[i].rstrip()+\"\\n\")\n","    o3.write(lines3[i].rstrip()+\"\\n\")\n","\n","o1.close()\n","o2.close()\n","o3.close()"],"metadata":{"id":"wnAJUliG5wqf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#No augmentation\n","\n","Target: \\bin"],"metadata":{"id":"lcoSIwuKEIMR"}},{"cell_type":"code","source":["!for GENRE in R1; do \\\n","    for SPLIT in trainr dev; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/fairseq/examples/roberta/multiprocessing_bpe_encoder.py \\\n","            --encoder-json gpt2_bpe/encoder.json \\\n","            --vocab-bpe gpt2_bpe/vocab.bpe \\\n","            --inputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/${SPLIT}.raw.${TYPE} \\\n","            --outputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/${SPLIT}.bpe.${TYPE} \\\n","            --keep-empty \\\n","            --workers 60; \\\n","      done \\\n","    done \\\n","  done"],"metadata":{"id":"_fc2YrvWEMV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!for GENRE in R1; do \\\n","    for TYPE in input0 input1; do \\\n","      fairseq-preprocess \\\n","      --only-source \\\n","      --srcdict gpt2_bpe/dict.txt \\\n","      --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/trainr.bpe.${TYPE} \\\n","      --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.bpe.${TYPE} \\\n","      --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.bpe.${TYPE} \\\n","      --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin/${TYPE} \\\n","      --workers 60;\\\n","    done \\\n","  done"],"metadata":{"id":"_hwFuJ8gEdBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!for GENRE in R1; do \\\n","    for TYPE in label; do \\\n","      fairseq-preprocess \\\n","      --only-source \\\n","      --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/trainr.raw.${TYPE} \\\n","      --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.raw.${TYPE} \\\n","      --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.raw.${TYPE} \\\n","      --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin/${TYPE} \\\n","      --workers 60;\\\n","    done \\\n","  done"],"metadata":{"id":"lyFtwPViFGVO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EDA\n","\n","Target: \\bin_eda"],"metadata":{"id":"UZpqBiNkFTwl"}},{"cell_type":"code","source":["import nltk; nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YG-PPGg6FyTE","executionInfo":{"status":"ok","timestamp":1686212045963,"user_tz":-120,"elapsed":2498,"user":{"displayName":"Louise Leibbrandt","userId":"11762724927321883770"}},"outputId":"914f6c97-e2cc-46f2-ceaf-e2faa9b2363a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import subprocess\n","\n","def execute_shell_command(command):\n","    process = subprocess.Popen(command, shell=True)\n","    process.wait()\n","\n","command = \"\"\"\n","for GENRE in R1; do \\\n","    for TYPE in input0 input1; do \\\n","        paste -d \"\\t\" /content/drive/MyDrive/NLP/anli/$GENRE/orig/trainr.raw.label /content/drive/MyDrive/NLP/anli/$GENRE/orig/trainr.raw.$TYPE > /content/drive/MyDrive/NLP/anli/$GENRE/orig/eda/train.combined.label.$TYPE; \\\n","    done \\\n","done\n","\"\"\"\n","\n","execute_shell_command(command)"],"metadata":{"id":"HgFCaJQqF3zM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess\n","\n","def execute_shell_command(command):\n","    process = subprocess.Popen(command, shell=True)\n","    process.wait()\n","\n","genres = ['R1']\n","types = ['input0', 'input1']\n","\n","for genre in genres:\n","    for type_ in types:\n","        command = f\"python /content/drive/MyDrive/NLP/augmentation/eda_nlp-master/code/augment.py \\\n","                    --input /content/drive/MyDrive/NLP/anli/{genre}/orig/eda/train.combined.label.{type_} \\\n","                    --num_aug=4\"\n","        execute_shell_command(command)"],"metadata":{"id":"9cRqWry_GB6Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","with tf.device('/device:GPU:0'):\n","  !for GENRE in R1; do \\\n","    for SPLIT in train; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/fairseq/examples/roberta/multiprocessing_bpe_encoder.py \\\n","            --encoder-json gpt2_bpe/encoder.json \\\n","            --vocab-bpe gpt2_bpe/vocab.bpe \\\n","            --inputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda/eda_${SPLIT}.combined.label.${TYPE} \\\n","            --outputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda/eda_${SPLIT}.combined.label.bpe.${TYPE} \\\n","            --keep-empty \\\n","            --workers 60; \\\n","      done \\\n","    done \\\n","  done"],"metadata":{"id":"Eyx9XUm9GEfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","with tf.device('/device:GPU:0'):\n","  !for GENRE in R1; do \\\n","    for SPLIT in dev test; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/fairseq/examples/roberta/multiprocessing_bpe_encoder.py \\\n","            --encoder-json gpt2_bpe/encoder.json \\\n","            --vocab-bpe gpt2_bpe/vocab.bpe \\\n","            --inputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/${SPLIT}.raw.${TYPE} \\\n","            --outputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/${SPLIT}.bpe.${TYPE} \\\n","            --keep-empty \\\n","            --workers 60; \\\n","      done \\\n","    done \\\n","  done"],"metadata":{"id":"TcSdwPaqGM5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the two input scentences\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in input0 input1; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --srcdict gpt2_bpe/dict.txt \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda/eda_train.combined.label.bpe.${TYPE}  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.bpe.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.bpe.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_eda2/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"mc_2iOQnGR2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the labels\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in label; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda/eda_label_train.combined.${TYPE}.input0  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.raw.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.raw.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_eda2/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"ajvZ-9ALGWGP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# UDA\n","\n","Target: \\bin_uda"],"metadata":{"id":"xqtihXXcoHkl"}},{"cell_type":"code","source":["! pip install transformers\n","! pip install sentencepiece"],"metadata":{"id":"ICSwtQ1R6698"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import MarianMTModel, MarianTokenizer\n","\n","torch.cuda.empty_cache()\n","\n","en_fr_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n","en_fr_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n","\n","fr_en_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n","fr_en_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")"],"metadata":{"id":"cJepJoRz69nN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code for translating input 0\n","input = open('/content/drive/MyDrive/NLP/anli/R1/orig/trainr.raw.input0', 'r')\n","src_text = input.read().splitlines()\n","\n","output = open('/content/drive/MyDrive/NLP/anli/R1/orig/translate/trans_train.raw.input0', 'w')\n","\n","for line in src_text:\n","  translated_tokens = en_fr_model.generate(**en_fr_tokenizer(line, return_tensors=\"pt\", padding=True), num_return_sequences = 2, top_k = 10, temperature = 2.0)\n","  en_fr = [en_fr_tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n","\n","  translated_tokens2 = fr_en_model.generate(**fr_en_tokenizer(en_fr, return_tensors=\"pt\", padding=True), num_return_sequences = 2, top_k = 10, temperature = 2.0)\n","  fr_en = [fr_en_tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens2]\n","  output.write(line.rstrip()+\"\\n\")\n","\n","  for r in fr_en:\n","    output.write(r.rstrip()+\"\\n\")\n","    output.flush()\n","\n","input.close()\n","output.close()"],"metadata":{"id":"5JCi0xgt7Aqx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Code for translating input 0\n","input = open('/content/drive/MyDrive/NLP/anli/R1/orig/trainr.raw.input1', 'r')\n","src_text = input.read().splitlines()\n","\n","output = open('/content/drive/MyDrive/NLP/anli/R1/orig/translate/trans_train.raw.input1', 'w')\n","\n","for line in src_text:\n","  translated_tokens = en_fr_model.generate(**en_fr_tokenizer(line, return_tensors=\"pt\", padding=True), num_return_sequences = 2, top_k = 10, temperature = 2.0)\n","  en_fr = [en_fr_tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n","\n","  translated_tokens2 = fr_en_model.generate(**fr_en_tokenizer(en_fr, return_tensors=\"pt\", padding=True), num_return_sequences = 2, top_k = 10, temperature = 2.0)\n","  fr_en = [fr_en_tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens2]\n","  output.write(line.rstrip()+\"\\n\")\n","\n","  for r in fr_en:\n","    output.write(r.rstrip()+\"\\n\")\n","    output.flush()\n","\n","input.close()\n","output.close()"],"metadata":{"id":"vUUGxJec7HhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create label file\n","f = open('/content/drive/MyDrive/NLP/anli/R1/orig/trainr.raw.label', 'r')\n","o = open('/content/drive/MyDrive/NLP/anli/R1/orig/translate/trans_train.raw.label', 'w')\n","\n","lines = f.read().splitlines()\n","print(len(lines))\n","for i in lines:\n","  for j in range (5):\n","    o.write(i.strip()+\"\\n\")\n","\n","\n","o.close()"],"metadata":{"id":"VizK8tN7oJ9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","with tf.device('/device:GPU:0'):\n","  !for GENRE in R1; do \\\n","    for SPLIT in train; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/fairseq/examples/roberta/multiprocessing_bpe_encoder.py \\\n","            --encoder-json gpt2_bpe/encoder.json \\\n","            --vocab-bpe gpt2_bpe/vocab.bpe \\\n","            --inputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/translate/trans_${SPLIT}.raw.${TYPE} \\\n","            --outputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/translate/trans_${SPLIT}.raw.bpe.${TYPE} \\\n","            --keep-empty \\\n","            --workers 60; \\\n","      done \\\n","    done \\\n","  done"],"metadata":{"id":"f9yVl3UuK0aQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the two input scentences\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in input0 input1; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --srcdict gpt2_bpe/dict.txt \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/translate/trans_train.raw.bpe.${TYPE}  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.bpe.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.bpe.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_uda/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"Sr-0IvM6K67Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the labels\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in label; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/translate/trans_train.raw.${TYPE}  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.raw.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.raw.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_uda/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zVr_gqlQLA4b","executionInfo":{"status":"ok","timestamp":1686483340411,"user_tz":-120,"elapsed":25871,"user":{"displayName":"Louise Leibbrandt","userId":"11762724927321883770"}},"outputId":"dc7e6d86-41d5-41c6-824d-9fc67fbe11ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-11 11:35:18.053865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-06-11 11:35:21 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang=None, target_lang=None, trainpref='/content/drive/MyDrive/NLP/anli/R1/orig/translate/trans_train.raw.label', validpref='/content/drive/MyDrive/NLP/anli/R1/orig/dev.raw.label', testpref='/content/drive/MyDrive/NLP/anli/R1/orig/test.raw.label', align_suffix=None, destdir='/content/drive/MyDrive/NLP/anli/R1/orig/bin_uda/label', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=True, padding_factor=8, workers=60, dict_only=False)\n","2023-06-11 11:35:24 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n","2023-06-11 11:35:31 | INFO | fairseq_cli.preprocess | [None] /content/drive/MyDrive/NLP/anli/R1/orig/translate/trans_train.raw.label: 50000 sents, 100000 tokens, 0.0% replaced (by <unk>)\n","2023-06-11 11:35:31 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n","2023-06-11 11:35:34 | INFO | fairseq_cli.preprocess | [None] /content/drive/MyDrive/NLP/anli/R1/orig/dev.raw.label: 1000 sents, 2000 tokens, 0.0% replaced (by <unk>)\n","2023-06-11 11:35:34 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n","2023-06-11 11:35:38 | INFO | fairseq_cli.preprocess | [None] /content/drive/MyDrive/NLP/anli/R1/orig/test.raw.label: 1000 sents, 2000 tokens, 0.0% replaced (by <unk>)\n","2023-06-11 11:35:38 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to /content/drive/MyDrive/NLP/anli/R1/orig/bin_uda/label\n"]}]},{"cell_type":"markdown","source":["# SSMBA\n","\n","Target: \\bin_ssmba"],"metadata":{"id":"-qXKnN52oKs-"}},{"cell_type":"code","source":["! git clone https://github.com/nng555/ssmba.git /content/drive/MyDrive/ssmba\n","! pip install -r /content/drive/MyDrive/ssmba/requirements.txt"],"metadata":{"id":"NeAJf8qg7uKh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess\n","import tensorflow as tf\n","\n","def execute_shell_command(command):\n","    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n","    stdout, stderr = process.communicate()\n","    return process.returncode, stdout, stderr\n","\n","with tf.device('/device:GPU:0'):\n","    for genre in ['fiction']:\n","        for split in ['trainr']:\n","            for type_ in ['input0 input1']:\n","                command = [\n","                    'python',\n","                    '/content/drive/MyDrive/ssmba/ssmba.py',\n","                    '--model', 'bert-base-uncased',\n","                    '--in-file', f'/content/drive/MyDrive/{genre}/orig/{split}.raw.{type_}',\n","                    '--label-file', f'/content/drive/MyDrive/{genre}/orig/{split}.raw.label',\n","                    '--output-prefix', f'ssmba_out',\n","                    '--noise-prob', '0.05',\n","                    '--num-samples', '5',\n","                ]\n","                returncode, stdout, stderr = execute_shell_command(command)\n","                if returncode != 0:\n","                    print(f\"Error running the command for {genre}/{split}/{type_}:\")\n","                    print(stderr)\n","                else:\n","                    print(f\"Command executed successfully for {genre}/{split}/{type_}:\")\n","                    print(stdout)"],"metadata":{"id":"1G8wpFvp7unr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f = open('/content/drive/MyDrive/NLP/anli/R1/orig/ssmba/ssmba_out', 'r')\n","o1 = open('/content/drive/MyDrive/NLP/anli/R1/orig/ssmba/ssmba_train.raw.input0', 'w')\n","o2 = open('/content/drive/MyDrive/NLP/anli/R1/orig/ssmba/ssmba_train.raw.input1', 'w')\n","\n","lines = [tuple(s.strip().split('\\t')) for s in f.readlines()]\n","\n","for i in range (len(lines)):\n","  o1.write(lines[i][0].strip()+\"\\n\")\n","  o2.write(lines[i][1].strip()+\"\\n\")\n","\n","\n","o1.close()\n","o2.close()\n"],"metadata":{"id":"Pxj1eTh1oVKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","with tf.device('/device:GPU:0'):\n","  !for GENRE in R1; do \\\n","    for SPLIT in train; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/fairseq/examples/roberta/multiprocessing_bpe_encoder.py \\\n","            --encoder-json gpt2_bpe/encoder.json \\\n","            --vocab-bpe gpt2_bpe/vocab.bpe \\\n","            --inputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/ssmba/ssmba_${SPLIT}.raw.${TYPE} \\\n","            --outputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/ssmba/ssmba_${SPLIT}.raw.bpe.${TYPE} \\\n","            --keep-empty \\\n","            --workers 60; \\\n","      done \\\n","    done \\\n","  done"],"metadata":{"id":"Ow3KDAOQsjLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the two input scentences\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in input0 input1; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --srcdict gpt2_bpe/dict.txt \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/ssmba/ssmba_train.raw.bpe.${TYPE}  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.bpe.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.bpe.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_ssmba/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"Oub0CjrhuVig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the labels\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in label; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/ssmba/ssmba_out.${TYPE}  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.raw.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.raw.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_ssmba/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"EGbQnONnu7v4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EDA_extended\n"],"metadata":{"id":"3kGf4K-YVz9T"}},{"cell_type":"code","source":["import nltk; nltk.download('wordnet')"],"metadata":{"id":"Ylso5rAMVzBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install python-utils"],"metadata":{"id":"k4OjXBbTXGxB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess\n","\n","def execute_shell_command(command):\n","    process = subprocess.Popen(command, shell=True)\n","    process.wait()\n","\n","command = \"\"\"\n","for GENRE in R1; do \\\n","    for TYPE in input0 input1; do \\\n","        paste -d \"\\t\" /content/drive/MyDrive/NLP/anli/$GENRE/orig/trainr.raw.label /content/drive/MyDrive/NLP/anli/$GENRE/orig/trainr.raw.$TYPE > /content/drive/MyDrive/NLP/anli/$GENRE/orig/eda_extended/train.combined.label.$TYPE; \\\n","    done \\\n","done\n","\"\"\"\n","\n","execute_shell_command(command)"],"metadata":{"id":"-HclOihAR01C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!for GENRE in R1; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/drive/MyDrive/NLP/eda_extended/augment.py \\\n","        --input /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda_extended/train.combined.label.${TYPE} \\\n","        --num_aug=4; \\\n","      done \\\n","    done"],"metadata":{"id":"W-Slv5NTSI2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","with tf.device('/device:GPU:0'):\n","  !for GENRE in R1; do \\\n","    for SPLIT in train; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/fairseq/examples/roberta/multiprocessing_bpe_encoder.py \\\n","            --encoder-json gpt2_bpe/encoder.json \\\n","            --vocab-bpe gpt2_bpe/vocab.bpe \\\n","            --inputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda_extended/eda_extended_${SPLIT}.combined.label.${TYPE} \\\n","            --outputs /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda_extended/eda_extended_${SPLIT}.combined.label.bpe.${TYPE} \\\n","            --keep-empty \\\n","            --workers 60; \\\n","      done \\\n","    done \\\n","  done"],"metadata":{"id":"QwwOgemtS8cs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the two input scentences\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in input0 input1; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --srcdict gpt2_bpe/dict.txt \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda_extended/eda_extended_train.combined.label.bpe.${TYPE}  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.bpe.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.bpe.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_eda_extended/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"u7TndyhLhT1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  # for the labels\n","with tf.device('/device:GPU:0'):\n","    !for GENRE in R1; do \\\n","      for TYPE in label; do \\\n","        fairseq-preprocess \\\n","        --only-source \\\n","        --trainpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda_extended/eda_label_extended_train.combined.${TYPE}.input0  \\\n","        --validpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/dev.raw.${TYPE} \\\n","        --testpref /content/drive/MyDrive/NLP/anli/${GENRE}/orig/test.raw.${TYPE} \\\n","        --destdir /content/drive/MyDrive/NLP/anli/${GENRE}/orig/bin_eda_extended/${TYPE} \\\n","        --workers 60;\\\n","      done \\\n","    done"],"metadata":{"id":"SVliUV4IhdLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import subprocess\n","\n","def execute_shell_command(command):\n","    process = subprocess.Popen(command, shell=True)\n","    process.wait()\n","\n","command = \"\"\"\n","for GENRE in R1; do \\\n","    for TYPE in input0 input1; do \\\n","        paste -d \"\\t\" /content/drive/MyDrive/NLP/anli/$GENRE/orig/trainr.raw.label /content/drive/MyDrive/NLP/anli/$GENRE/orig/trainr.raw.$TYPE > /content/drive/MyDrive/NLP/anli/$GENRE/orig/eda_extended2/train.combined.label.$TYPE; \\\n","    done \\\n","done\n","\"\"\"\n","\n","execute_shell_command(command)"],"metadata":{"id":"-TkeP70ux4fm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!for GENRE in R1; do \\\n","      for TYPE in input0 input1; do \\\n","        python /content/drive/MyDrive/NLP/eda_extended_without_tfidf/code/augment.py \\\n","        --input /content/drive/MyDrive/NLP/anli/${GENRE}/orig/eda_extended2/train.combined.label.${TYPE} \\\n","        --num_aug=4; \\\n","      done \\\n","    done"],"metadata":{"id":"ATr45lgLyRGm"},"execution_count":null,"outputs":[]}]}